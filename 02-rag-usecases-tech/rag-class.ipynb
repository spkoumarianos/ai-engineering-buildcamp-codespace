{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244b9b31-5fcf-495b-9545-ac4bccba891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 385 chunks from 95 documents\n"
     ]
    }
   ],
   "source": [
    "import rag\n",
    "index = rag.initialize_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1759ad79-4e80-4f04-97a2-5b635459727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0150fee-c40e-430b-be55-2e9c02c1678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_rag = rag.RAG(index=index, llm_client=openai_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f782bdd-d2a9-49c0-ab09-d559db06e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = doc_rag.rag('llm as a judge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4982dc-2a07-4913-a558-3118af5e83c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using an LLM (Large Language Model) as a judge involves evaluating text responses against custom criteria, and it can be implemented in two main ways:\n",
      "\n",
      "1. **Reference-based Evaluation**: This method involves comparing new responses against a predetermined correct answer (ground truth). It is beneficial for regression testing and scenarios where a definitive answer exists.\n",
      "\n",
      "2. **Open-ended Evaluation**: In this approach, the evaluations are based on custom criteria without requiring a reference answer. This is useful for situations where new outputs need to be assessed without prior examples.\n",
      "\n",
      "The tutorial outlines the following key steps to create and evaluate an LLM as a judge:\n",
      "- **Create an Evaluation Dataset**: Develop a dataset that includes questions, target responses, new responses, and manual labels indicating whether the responses are correct.\n",
      "- **Set Up and Run the LLM Judge**: Design prompts for the LLM evaluator and evaluate its performance.\n",
      "- **Evaluate the Quality of the LLM Evaluator**: This step checks how well the LLM performs when predicting labels against manual evaluations, with metrics such as accuracy, precision, and recall.\n",
      "\n",
      "This tutorial is executed in a Python environment (Jupyter Notebook or Google Colab) and requires an OpenAI API key to access the LLM functionalities.\n"
     ]
    }
   ],
   "source": [
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee83bd2-f8ac-4b73-b668-405c0cfbbf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found answer: True\n",
      "Confidence: 0.95\n",
      "Answer type: how-to\n",
      "Follow-up questions: ['What tools are needed to implement the LLM judge?', 'Can the LLM judge be modified for different evaluation contexts?', 'What are the advantages of using an LLM as a judge?']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found answer: {response.found_answer}\")\n",
    "print(f\"Confidence: {response.confidence}\")\n",
    "print(f\"Answer type: {response.answer_type}\")\n",
    "print(f\"Follow-up questions: {response.followup_questions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f19f6-3595-43d8-8e32-b09655bbc7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
