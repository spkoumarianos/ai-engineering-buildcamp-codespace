{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m237 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m232 packages\u001b[0m \u001b[2min 46ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add pydantic_ai\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from urllib.parse import quote_plus, unquote, urlparse\n",
    "\n",
    "from pydantic_ai import Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKIPEDIA_SEARCH_API = \"https://en.wikipedia.org/w/api.php\"\n",
    "WIKIPEDIA_RAW_API = \"https://en.wikipedia.org/w/index.php\"\n",
    "USER_AGENT = \"tool-call-loop-wikipedia/1.0 (learning project)\"\n",
    "\n",
    "\n",
    "def _title_from_url(url: str) -> str:\n",
    "    parsed = urlparse(url)\n",
    "    if \"/wiki/\" in parsed.path:\n",
    "        return unquote(parsed.path.split(\"/wiki/\", 1)[1]).replace(\"_\", \" \")\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def search(query: str, limit: int | None = None):\n",
    "    \"\"\"Search Wikipedia and return a near-original API payload.\"\"\"\n",
    "    url = (\n",
    "        \"https://en.wikipedia.org/w/api.php\"\n",
    "        f\"?action=query&format=json&list=search&srsearch={quote_plus(query)}\"\n",
    "    )\n",
    "    if limit is not None:\n",
    "        url += f\"&srlimit={limit}\"\n",
    "\n",
    "    r = requests.get(url, timeout=15, headers={\"User-Agent\": USER_AGENT})\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    return {\n",
    "        \"batchcomplete\": data.get(\"batchcomplete\", \"\"),\n",
    "        \"continue\": data.get(\"continue\"),\n",
    "        \"query\": data.get(\"query\", {}),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_page(page_title: str):\n",
    "    \"\"\"Fetch raw Wikipedia page content by title or URL.\"\"\"\n",
    "    title = page_title\n",
    "    if page_title.startswith(\"http://\") or page_title.startswith(\"https://\"):\n",
    "        extracted = _title_from_url(page_title)\n",
    "        if extracted:\n",
    "            title = extracted\n",
    "\n",
    "    url = f\"{WIKIPEDIA_RAW_API}?title={quote_plus(title)}&action=raw\"\n",
    "    r = requests.get(url, timeout=15, headers={\"User-Agent\": USER_AGENT})\n",
    "    r.raise_for_status()\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"url\": url,\n",
    "        \"content\": r.text,\n",
    "        \"source\": \"wikipedia\",\n",
    "    }\n",
    "\n",
    "\n",
    "def count_page_characters(page_title: str):\n",
    "    \"\"\"Return exact character count for a Wikipedia page.\"\"\"\n",
    "    page = get_page(page_title)\n",
    "    return {\n",
    "        \"title\": page[\"title\"],\n",
    "        \"url\": page[\"url\"],\n",
    "        \"character_count\": len(page[\"content\"]),\n",
    "        \"source\": \"wikipedia\",\n",
    "    }\n",
    "\n",
    "\n",
    "def count_titles_with_term(query: str, term: str, limit: int | None = None):\n",
    "    \"\"\"Count returned search result titles containing a whole-word term, case-insensitive.\"\"\"\n",
    "    payload = search(query=query, limit=limit)\n",
    "    search_items = payload.get(\"query\", {}).get(\"search\", [])\n",
    "\n",
    "    pattern = re.compile(rf\"\\b{re.escape(term)}\\b\", flags=re.IGNORECASE)\n",
    "    matched_titles = []\n",
    "    for item in search_items:\n",
    "        title = item.get(\"title\", \"\")\n",
    "        if pattern.search(title):\n",
    "            matched_titles.append(title)\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"term\": term,\n",
    "        \"title_match_count\": len(matched_titles),\n",
    "        \"matched_titles\": matched_titles,\n",
    "        \"search_returned_count\": len(search_items),\n",
    "        \"source\": \"wikipedia\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tool_calls(messages):\n",
    "    found = False\n",
    "    for m in messages:\n",
    "        for p in m.parts:\n",
    "            part_kind = getattr(p, \"part_kind\", None)\n",
    "            if part_kind == \"tool-call\":\n",
    "                print(f\"TOOL CALL: {p.tool_name}({p.args})\")\n",
    "                found = True\n",
    "            if part_kind == \"tool-return\":\n",
    "                print(f\"TOOL RETURN: {p.tool_name}\")\n",
    "    if not found:\n",
    "        print(\"TOOL CALL: none\")\n",
    "\n",
    "\n",
    "def print_assistant_text(messages):\n",
    "    for m in messages:\n",
    "        for p in m.parts:\n",
    "            if getattr(p, \"part_kind\", None) == \"text\":\n",
    "                print(\"ASSISTANT:\", p.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You're a Wikipedia research assistant.\n",
    "\n",
    "Use tools for factual retrieval.\n",
    "Rules:\n",
    "- For result-count questions, use query.search length from search output.\n",
    "- For total matches, use query.searchinfo.totalhits.\n",
    "- For title-only counting questions, call count_titles_with_term.\n",
    "- For character-count questions, call count_page_characters.\n",
    "\"\"\"\n",
    "\n",
    "wiki_agent = Agent(\n",
    "    name=\"wikipedia-tools\",\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    instructions=instructions,\n",
    "    tools=[search, get_page, count_page_characters, count_titles_with_term],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    # \"How many results are returned by searching for capybara?\",\n",
    "    # \"How many total matches exist for capybara?\",\n",
    "    # \"How many of those returned results contain the word capybara in the title?\",\n",
    "    # \"How many characters are in the Wikipedia page for Capybara?\",\n",
    "    # = \"What is this page about? https://en.wikipedia.org/wiki/Capybara\"\n",
    "    \"What are the main threats to capybara populations?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Query 1 ===\n",
      "USER: What are the main threats to capybara populations?\n",
      "TOOL CALL: search({\"query\":\"capybara threats\",\"limit\":5})\n",
      "TOOL RETURN: search\n",
      "TOOL CALL: search({\"query\":\"capybara\",\"limit\":5})\n",
      "TOOL RETURN: search\n",
      "TOOL CALL: get_page({\"page_title\":\"Capybara\"})\n",
      "TOOL RETURN: get_page\n",
      "ASSISTANT: The main threats to capybara populations include:\n",
      "\n",
      "1. **Hunting**: Capybaras are hunted for their meat and hides, which is a significant threat in some regions of South America where hunting is prevalent.\n",
      "\n",
      "2. **Habitat Loss**: Their natural habitats are often destroyed due to agricultural expansion, urban development, and land conversion for livestock. This leads to a reduction in their living spaces and food availability.\n",
      "\n",
      "3. **Human-Wildlife Conflict**: In some areas, capybaras are perceived as competition for livestock grazing, leading to them being killed by farmers.\n",
      "\n",
      "4. **Predation**: Natural predators such as big cats (jaguars and cougars), caimans, and anacondas pose a constant threat to capybara populations, particularly to younger individuals.\n",
      "\n",
      "5. **Urbanization**: Capybaras have adapted to urban environments to some degree, but urban encroachment can still pose risks, including vehicle strikes and conflicts with humans.\n",
      "\n",
      "Despite these threats, capybara populations are currently considered stable in most areas, although localized declines are observed due to human activities. The species is not classified as threatened overall, but conservation efforts are necessary in some regions to mitigate these threats.\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "\n",
    "for i, query in enumerate(queries, start=1):\n",
    "    print(f\"\\n=== Query {i} ===\")\n",
    "    print(\"USER:\", query)\n",
    "\n",
    "    result = await wiki_agent.run(query, message_history=messages)\n",
    "    new_messages = result.new_messages()\n",
    "\n",
    "    print_tool_calls(new_messages)\n",
    "    print_assistant_text(new_messages)\n",
    "\n",
    "    messages.extend(new_messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(parts=[TextPart(content='The main threats to capybara populations include:\\n\\n1. **Hunting**: Capybaras are hunted for their meat and hides, which is a significant threat in some regions of South America where hunting is prevalent.\\n\\n2. **Habitat Loss**: Their natural habitats are often destroyed due to agricultural expansion, urban development, and land conversion for livestock. This leads to a reduction in their living spaces and food availability.\\n\\n3. **Human-Wildlife Conflict**: In some areas, capybaras are perceived as competition for livestock grazing, leading to them being killed by farmers.\\n\\n4. **Predation**: Natural predators such as big cats (jaguars and cougars), caimans, and anacondas pose a constant threat to capybara populations, particularly to younger individuals.\\n\\n5. **Urbanization**: Capybaras have adapted to urban environments to some degree, but urban encroachment can still pose risks, including vehicle strikes and conflicts with humans.\\n\\nDespite these threats, capybara populations are currently considered stable in most areas, although localized declines are observed due to human activities. The species is not classified as threatened overall, but conservation efforts are necessary in some regions to mitigate these threats.')], usage=RequestUsage(input_tokens=12560, cache_read_tokens=1280, output_tokens=251, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}), model_name='gpt-4o-mini-2024-07-18', timestamp=datetime.datetime(2026, 2, 16, 18, 51, 29, 778309, tzinfo=datetime.timezone.utc), provider_name='openai', provider_url='https://api.openai.com/v1/', provider_details={'finish_reason': 'stop', 'timestamp': datetime.datetime(2026, 2, 16, 18, 51, 20, tzinfo=TzInfo(0))}, provider_response_id='chatcmpl-D9xyiJ2yaq0c4J9GOF8PkyY9Q7IZI', finish_reason='stop', run_id='d435805b-721c-43f0-b85d-c05e59dc96dd')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[-1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineering-buildcamp-codespace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
